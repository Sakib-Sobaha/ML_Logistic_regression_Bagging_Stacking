{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, iterations=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            linear_pred = np.dot(X, self.weights) + self.bias\n",
    "            predictions = self.sigmoid(linear_pred)\n",
    "\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1 / n_samples) * np.sum(predictions - y)\n",
    "\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_pred = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = self.sigmoid(linear_pred)\n",
    "        return (y_pred > 0.5).astype(int)\n",
    "\n",
    "class BaggingClassifier:\n",
    "    def __init__(self, base_estimator, n_estimators=10):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        for _ in range(self.n_estimators):\n",
    "            estimator = self.base_estimator()\n",
    "            indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            X_sample, y_sample = X[indices], y[indices]\n",
    "            estimator.fit(X_sample, y_sample)\n",
    "            self.estimators.append(estimator)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([est.predict(X) for est in self.estimators])\n",
    "        return np.round(np.mean(predictions, axis=0)).astype(int)\n",
    "\n",
    "class StackingClassifier:\n",
    "    def __init__(self, base_estimators: List[Tuple[str, object]], final_estimator: object):\n",
    "        self.base_estimators = base_estimators\n",
    "        self.final_estimator = final_estimator\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Fit base estimators\n",
    "        for name, estimator in self.base_estimators:\n",
    "            estimator.fit(X, y)\n",
    "\n",
    "        # Generate meta-features\n",
    "        meta_features = self._get_meta_features(X)\n",
    "\n",
    "        # Fit final estimator\n",
    "        self.final_estimator.fit(meta_features, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        meta_features = self._get_meta_features(X)\n",
    "        return self.final_estimator.predict(meta_features)\n",
    "\n",
    "    def _get_meta_features(self, X):\n",
    "        return np.column_stack([est.predict(X) for _, est in self.base_estimators])\n",
    "\n",
    "# Helper function to split data\n",
    "def train_test_split(X, y, test_size=0.2):\n",
    "    n_samples = X.shape[0]\n",
    "    n_test = int(n_samples * test_size)\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    test_indices = indices[:n_test]\n",
    "    train_indices = indices[n_test:]\n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "# Helper function to calculate accuracy\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "# Generate a simple dataset\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(1000, 20)\n",
    "y = (X[:, 0] + X[:, 1] > 0).astype(int)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Logistic Regression with Bagging\n",
    "bagging_lr = BaggingClassifier(LogisticRegression, n_estimators=10)\n",
    "bagging_lr.fit(X_train, y_train)\n",
    "bagging_pred = bagging_lr.predict(X_test)\n",
    "\n",
    "# Logistic Regression with Stacking\n",
    "base_models = [\n",
    "    ('lr1', LogisticRegression()),\n",
    "    ('lr2', LogisticRegression()),\n",
    "    ('lr3', LogisticRegression())\n",
    "]\n",
    "stacking_lr = StackingClassifier(base_models, LogisticRegression())\n",
    "stacking_lr.fit(X_train, y_train)\n",
    "stacking_pred = stacking_lr.predict(X_test)\n",
    "\n",
    "# Simple Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Bagging Accuracy:\", accuracy_score(y_test, bagging_pred))\n",
    "print(\"Stacking Accuracy:\", accuracy_score(y_test, stacking_pred))\n",
    "print(\"Simple Logistic Regression Accuracy:\", accuracy_score(y_test, lr_pred))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
